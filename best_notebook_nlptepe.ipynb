{
  "nbformat": 4,
  "nbformat_minor": 0,
     "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abc6e04fa12a414b87605c57a1f87a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc925fb805f54f3a8e34b8e8403f092a",
              "IPY_MODEL_ed982a38d8a746ac841a055eb36184f8",
              "IPY_MODEL_21c8aa059c13446ba0bc38617eaab043"
            ],
            "layout": "IPY_MODEL_e1af346c1b5c4a1ab8b9055cb113fedc"
          }
        },
        "fc925fb805f54f3a8e34b8e8403f092a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3116ec6050674c80ab11162c2b895aa6",
            "placeholder": "​",
            "style": "IPY_MODEL_724a49673fa94b699979c8b6000aa6e5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ed982a38d8a746ac841a055eb36184f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6134193c2041dc82c1b5ba360f927a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dec6ddd3e4774bfe955e7e5e68b83bac",
            "value": 2
          }
        },
        "21c8aa059c13446ba0bc38617eaab043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b84ee9882adb47d4be79417cc745b827",
            "placeholder": "​",
            "style": "IPY_MODEL_6fefd9bd6241409fb67ee8e8842223cd",
            "value": " 2/2 [00:01&lt;00:00,  1.08it/s]"
          }
        },
        "e1af346c1b5c4a1ab8b9055cb113fedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3116ec6050674c80ab11162c2b895aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724a49673fa94b699979c8b6000aa6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef6134193c2041dc82c1b5ba360f927a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec6ddd3e4774bfe955e7e5e68b83bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b84ee9882adb47d4be79417cc745b827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fefd9bd6241409fb67ee8e8842223cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      
        "id": "xjcvs5hOi2Zg",
        "outputId": "445422b1-ccca-4856-a7f4-2b96cd1324c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dots.ocr'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 204 (delta 42), reused 30 (delta 30), pack-reused 149 (from 2)\u001b[K\n",
            "Receiving objects: 100% (204/204), 35.84 MiB | 21.92 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "/content/dots.ocr\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rednote-hilab/dots.ocr.git\n",
        "%cd dots.ocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128\n",
        "!pip install -e ."
      ],
              "id": "LMxBdXbuj5vr",
        "outputId": "370d3e11-1ec5-4ee7-e997-666293253a10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
            "Collecting torch==2.7.0\n",
            "  Downloading https://download.pytorch.org/whl/cu128/torch-2.7.0%2Bcu128-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision==0.22.0\n",
            "  Downloading https://download.pytorch.org/whl/cu128/torchvision-0.22.0%2Bcu128-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio==2.7.0\n",
            "  Downloading https://download.pytorch.org/whl/cu128/torchaudio-2.7.0%2Bcu128-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (4.14.1)\n",
            "Collecting sympy>=1.13.3 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.61 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.57 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.57 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.7.1.26 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cudnn_cu12-9.7.1.26-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.3.14 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.41 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.55 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.2.55 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.7.53 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.55 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.55-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.61 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.0.11 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.0.11-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch==2.7.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.22.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.22.0) (11.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu128/torch-2.7.0%2Bcu128-cp311-cp311-manylinux_2_28_x86_64.whl (1097.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 GB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/torchvision-0.22.0%2Bcu128-cp311-cp311-manylinux_2_28_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/torchaudio-2.7.0%2Bcu128-cp311-cp311-manylinux_2_28_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl (609.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m609.6/609.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cudnn_cu12-9.7.1.26-py3-none-manylinux_2_27_x86_64.whl (726.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m726.9/726.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.0.11-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl (260.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.4/260.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (292.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.2/39.2 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.55-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu128 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.3.14 nvidia-cuda-cupti-cu12-12.8.57 nvidia-cuda-nvrtc-cu12-12.8.61 nvidia-cuda-runtime-cu12-12.8.57 nvidia-cudnn-cu12-9.7.1.26 nvidia-cufft-cu12-11.3.3.41 nvidia-cufile-cu12-1.13.0.11 nvidia-curand-cu12-10.3.9.55 nvidia-cusolver-cu12-11.7.2.55 nvidia-cusparse-cu12-12.5.7.53 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.8.61 nvidia-nvtx-cu12-12.8.55 sympy-1.13.3 torch-2.7.0+cu128 torchaudio-2.7.0+cu128 torchvision-0.22.0+cu128 triton-3.3.0\n",
            "Obtaining file:///content/dots.ocr\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from dots_ocr==1.0) (5.42.0)\n",
            "Collecting gradio_image_annotation (from dots_ocr==1.0)\n",
            "  Downloading gradio_image_annotation-0.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting PyMuPDF (from dots_ocr==1.0)\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from dots_ocr==1.0) (1.99.8)\n",
            "Collecting qwen_vl_utils (from dots_ocr==1.0)\n",
            "  Downloading qwen_vl_utils-0.0.11-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting transformers==4.51.3 (from dots_ocr==1.0)\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from dots_ocr==1.0) (0.34.4)\n",
            "Collecting modelscope (from dots_ocr==1.0)\n",
            "  Downloading modelscope-1.29.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flash-attn==2.8.0.post2 (from dots_ocr==1.0)\n",
            "  Downloading flash_attn-2.8.0.post2.tar.gz (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from dots_ocr==1.0) (1.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.8.0.post2->dots_ocr==1.0) (2.7.0+cu128)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.8.0.post2->dots_ocr==1.0) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->dots_ocr==1.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->dots_ocr==1.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->dots_ocr==1.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->dots_ocr==1.0) (1.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->dots_ocr==1.0) (5.9.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (3.11.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.12.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->dots_ocr==1.0) (0.35.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.1->gradio->dots_ocr==1.0) (15.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope->dots_ocr==1.0) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope->dots_ocr==1.0) (2.5.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->dots_ocr==1.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->dots_ocr==1.0) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->dots_ocr==1.0) (1.3.1)\n",
            "Collecting av (from qwen_vl_utils->dots_ocr==1.0)\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->dots_ocr==1.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio->dots_ocr==1.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio->dots_ocr==1.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->dots_ocr==1.0) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->dots_ocr==1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->dots_ocr==1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->dots_ocr==1.0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->dots_ocr==1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->dots_ocr==1.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->dots_ocr==1.0) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3->dots_ocr==1.0) (3.4.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.8.61)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.8.57)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.8.57)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (9.7.1.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.8.3.14)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (11.3.3.41)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (10.3.9.55)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (11.7.2.55)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.5.7.53)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.8.55)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (12.8.61)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (1.13.0.11)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (3.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->dots_ocr==1.0) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->dots_ocr==1.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->dots_ocr==1.0) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio->dots_ocr==1.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->dots_ocr==1.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->dots_ocr==1.0) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->flash-attn==2.8.0.post2->dots_ocr==1.0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->dots_ocr==1.0) (0.1.2)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_image_annotation-0.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.29.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qwen_vl_utils-0.0.11-py3-none-any.whl (7.6 kB)\n",
            "Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.8.0.post2-cp311-cp311-linux_x86_64.whl size=255941661 sha256=8ed71ac092f80b079d2e6043b769135904d6e834916cb6da7d372b394581447b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/75/55/57ba1e272fd7fa1a01d9ba6b5334b7adaabf79900ede22c040\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: PyMuPDF, av, qwen_vl_utils, modelscope, transformers, flash-attn, gradio_image_annotation, dots_ocr\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.0\n",
            "    Uninstalling transformers-4.55.0:\n",
            "      Successfully uninstalled transformers-4.55.0\n",
            "  Running setup.py develop for dots_ocr\n",
            "Successfully installed PyMuPDF-1.26.3 av-15.0.0 dots_ocr-1.0 flash-attn-2.8.0.post2 gradio_image_annotation-0.4.0 modelscope-1.29.0 qwen_vl_utils-0.0.11 transformers-4.51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 tools/download_model.py\n"
      ],
              "outputId": "5a1cfc0c-9da5-4d93-b60a-6cfac8f30a64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention: The model save dir dots.ocr should be replace by a name without `.` like DotsOCR, util we merge our code to transformers.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "Fetching 20 files:   0% 0/20 [00:00<?, ?it/s]\n",
            "config.json: 1.47kB [00:00, 2.72MB/s]\n",
            "\n",
            "configuration_dots.py: 2.93kB [00:00, 4.89MB/s]\n",
            "\n",
            "generation_config.json: 100% 74.0/74.0 [00:00<00:00, 813kB/s]\n",
            "\n",
            "README.md: 31.1kB [00:00, 71.5MB/s]\n",
            "\n",
            "NOTICE: 118kB [00:00, 57.4MB/s]\n",
            "\n",
            "chat_template.json: 1.11kB [00:00, 6.87MB/s]\n",
            "\n",
            "dots.ocr%20LICENSE%20AGREEMENT: 15.5kB [00:00, 47.6MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.29G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model.safetensors.index.json: 52.2kB [00:00, 158MB/s]\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.79G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "modeling_dots_ocr_vllm.py: 17.5kB [00:00, 60.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "modeling_dots_ocr.py: 4.98kB [00:00, 25.0MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.29G [00:00<00:31, 134MB/s]\u001b[A\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 494/494 [00:00<00:00, 5.04MB/s]\n",
            "\n",
            "\n",
            "\n",
            "preprocessor_config.json: 100% 347/347 [00:00<00:00, 3.85MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.json: 7.04MB [00:00, 89.8MB/s]\n",
            "\n",
            "\n",
            "\n",
            "modeling_dots_vision.py: 14.9kB [00:00, 46.6MB/s]\n",
            "\n",
            "\n",
            "\n",
            ".gitattributes: 1.52kB [00:00, 7.53MB/s]\n",
            "Fetching 20 files:   5% 1/20 [00:00<00:10,  1.77it/s]\n",
            "\n",
            "\n",
            "merges.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.29G [00:00<00:21, 195MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "vocab.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 52.4M/1.79G [00:00<00:08, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 9.31kB [00:00, 48.6MB/s]\n",
            "merges.txt: 1.67MB [00:00, 32.6MB/s]\n",
            "vocab.json: 2.78MB [00:00, 50.2MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.29G [00:00<00:18, 230MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 83.9M/1.79G [00:00<00:06, 247MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 115M/4.29G [00:00<00:16, 256MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 115M/1.79G [00:00<00:06, 267MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.29G [00:00<00:15, 264MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 147M/1.79G [00:00<00:05, 275MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 178M/1.79G [00:00<00:05, 284MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.29G [00:00<00:15, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 210M/4.29G [00:00<00:14, 276MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  12% 220M/1.79G [00:00<00:05, 298MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 241M/4.29G [00:00<00:14, 285MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 252M/1.79G [00:00<00:05, 301MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 273M/4.29G [00:01<00:13, 288MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 283M/1.79G [00:01<00:04, 303MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 304M/4.29G [00:01<00:13, 289MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  18% 315M/1.79G [00:01<00:04, 303MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 336M/4.29G [00:01<00:13, 288MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 346M/1.79G [00:01<00:04, 292MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 367M/4.29G [00:01<00:13, 285MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  21% 377M/1.79G [00:01<00:04, 284MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 398M/4.29G [00:01<00:13, 282MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  23% 409M/1.79G [00:01<00:04, 278MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 430M/4.29G [00:01<00:13, 279MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 440M/1.79G [00:01<00:04, 279MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 461M/4.29G [00:01<00:13, 278MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 472M/1.79G [00:01<00:04, 280MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 493M/4.29G [00:01<00:13, 279MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 503M/1.79G [00:01<00:04, 285MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 535M/1.79G [00:01<00:04, 293MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 524M/4.29G [00:01<00:13, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 556M/4.29G [00:02<00:13, 279MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  32% 577M/1.79G [00:02<00:03, 306MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 608M/1.79G [00:02<00:03, 303MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 587M/4.29G [00:02<00:13, 277MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 640M/1.79G [00:02<00:03, 295MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 619M/4.29G [00:02<00:13, 277MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  38% 671M/1.79G [00:02<00:04, 248MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 650M/4.29G [00:02<00:15, 236MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 703M/1.79G [00:02<00:04, 238MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 682M/4.29G [00:02<00:16, 220MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 734M/1.79G [00:02<00:04, 250MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 713M/4.29G [00:02<00:16, 219MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 765M/1.79G [00:02<00:05, 199MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 744M/4.29G [00:02<00:18, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 765M/4.29G [00:03<00:19, 183MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 797M/1.79G [00:03<00:05, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  46% 818M/1.79G [00:03<00:05, 172MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 786M/4.29G [00:03<00:21, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 807M/4.29G [00:03<00:22, 156MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 849M/1.79G [00:03<00:05, 164MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 828M/4.29G [00:03<00:25, 136MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  49% 870M/1.79G [00:03<00:05, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 849M/4.29G [00:03<00:23, 147MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 891M/1.79G [00:03<00:05, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 870M/4.29G [00:03<00:23, 147MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  51% 912M/1.79G [00:03<00:06, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 933M/1.79G [00:04<00:06, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 891M/4.29G [00:04<00:29, 113MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 965M/1.79G [00:04<00:04, 172MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 923M/4.29G [00:06<01:49, 30.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 986M/1.79G [00:06<00:25, 31.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 954M/4.29G [00:06<01:14, 44.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 1.02G/1.79G [00:06<00:16, 46.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 986M/4.29G [00:06<00:52, 62.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  59% 1.05G/1.79G [00:06<00:11, 64.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.02G/4.29G [00:06<00:38, 84.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 1.08G/1.79G [00:06<00:08, 86.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.05G/4.29G [00:06<00:29, 108MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 1.11G/1.79G [00:06<00:06, 111MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.08G/4.29G [00:06<00:24, 133MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 1.14G/1.79G [00:06<00:04, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.11G/4.29G [00:07<00:20, 158MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 1.17G/1.79G [00:07<00:03, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.14G/4.29G [00:07<00:17, 179MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 1.21G/1.79G [00:07<00:03, 184MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.17G/4.29G [00:07<00:15, 198MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 1.24G/1.79G [00:07<00:02, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 1.27G/1.79G [00:07<00:02, 227MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.21G/4.29G [00:07<00:16, 189MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 1.30G/1.79G [00:07<00:02, 240MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.24G/4.29G [00:07<00:15, 196MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 1.33G/1.79G [00:07<00:01, 258MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  76% 1.36G/1.79G [00:07<00:01, 272MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.27G/4.29G [00:07<00:14, 212MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 1.39G/1.79G [00:07<00:01, 279MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.30G/4.29G [00:07<00:13, 225MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.43G/1.79G [00:07<00:01, 279MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.33G/4.29G [00:08<00:12, 238MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 1.46G/1.79G [00:08<00:01, 287MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.36G/4.29G [00:08<00:11, 244MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.49G/1.79G [00:08<00:01, 284MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.39G/4.29G [00:08<00:11, 257MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 1.52G/1.79G [00:08<00:00, 282MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.43G/4.29G [00:08<00:10, 264MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 1.55G/1.79G [00:08<00:00, 281MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.46G/4.29G [00:08<00:10, 268MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 1.58G/1.79G [00:08<00:00, 279MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.49G/4.29G [00:08<00:10, 273MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 1.61G/1.79G [00:08<00:00, 275MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.52G/4.29G [00:08<00:10, 264MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 1.65G/1.79G [00:08<00:00, 271MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.55G/4.29G [00:08<00:10, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.58G/4.29G [00:08<00:10, 257MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 1.68G/1.79G [00:08<00:00, 238MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.61G/4.29G [00:09<00:13, 203MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 1.71G/1.79G [00:09<00:00, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 1.73G/1.79G [00:09<00:00, 187MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.65G/4.29G [00:09<00:13, 193MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  98% 1.75G/1.79G [00:09<00:00, 170MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.67G/4.29G [00:09<00:14, 179MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 1.77G/1.79G [00:09<00:00, 147MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.69G/4.29G [00:09<00:16, 160MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.79G/1.79G [00:09<00:00, 179MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.73G/4.29G [00:10<00:19, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.75G/4.29G [00:10<00:25, 99.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.78G/4.29G [00:10<00:19, 131MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.81G/4.29G [00:10<00:15, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.85G/4.29G [00:10<00:13, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.88G/4.29G [00:10<00:11, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.91G/4.29G [00:10<00:10, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.94G/4.29G [00:11<00:09, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.97G/4.29G [00:11<00:09, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.00G/4.29G [00:11<00:08, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.03G/4.29G [00:11<00:08, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.07G/4.29G [00:11<00:08, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.10G/4.29G [00:11<00:07, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.13G/4.29G [00:11<00:07, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.16G/4.29G [00:11<00:07, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.19G/4.29G [00:11<00:07, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.22G/4.29G [00:12<00:07, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.25G/4.29G [00:12<00:07, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.29G/4.29G [00:12<00:07, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.32G/4.29G [00:12<00:07, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.35G/4.29G [00:12<00:06, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.38G/4.29G [00:12<00:06, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.41G/4.29G [00:12<00:06, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.44G/4.29G [00:12<00:06, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.47G/4.29G [00:12<00:06, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.51G/4.29G [00:13<00:06, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.54G/4.29G [00:13<00:06, 292MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.57G/4.29G [00:13<00:05, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.60G/4.29G [00:13<00:06, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.63G/4.29G [00:13<00:05, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.66G/4.29G [00:13<00:05, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.69G/4.29G [00:13<00:05, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.73G/4.29G [00:13<00:05, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.76G/4.29G [00:13<00:05, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.79G/4.29G [00:14<00:05, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.82G/4.29G [00:14<00:05, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.85G/4.29G [00:14<00:05, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.88G/4.29G [00:14<00:05, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.92G/4.29G [00:14<00:04, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.95G/4.29G [00:14<00:04, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.98G/4.29G [00:14<00:04, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.01G/4.29G [00:14<00:04, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.04G/4.29G [00:14<00:04, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.07G/4.29G [00:15<00:04, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.10G/4.29G [00:15<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.14G/4.29G [00:15<00:04, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.17G/4.29G [00:15<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.20G/4.29G [00:15<00:04, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.23G/4.29G [00:15<00:03, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.26G/4.29G [00:15<00:03, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.29G/4.29G [00:15<00:03, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.32G/4.29G [00:16<00:03, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.36G/4.29G [00:16<00:03, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.39G/4.29G [00:16<00:03, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.42G/4.29G [00:16<00:03, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.45G/4.29G [00:16<00:03, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.48G/4.29G [00:16<00:02, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 3.51G/4.29G [00:16<00:02, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.54G/4.29G [00:16<00:02, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.58G/4.29G [00:16<00:02, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.61G/4.29G [00:17<00:02, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.64G/4.29G [00:17<00:02, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.67G/4.29G [00:17<00:02, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.70G/4.29G [00:17<00:02, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.73G/4.29G [00:17<00:01, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.76G/4.29G [00:17<00:02, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.80G/4.29G [00:17<00:01, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.83G/4.29G [00:17<00:01, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.86G/4.29G [00:18<00:01, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.89G/4.29G [00:18<00:01, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.92G/4.29G [00:18<00:01, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.95G/4.29G [00:18<00:01, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.98G/4.29G [00:18<00:01, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.02G/4.29G [00:18<00:01, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.05G/4.29G [00:18<00:00, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.08G/4.29G [00:18<00:00, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.11G/4.29G [00:18<00:00, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.14G/4.29G [00:19<00:00, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.17G/4.29G [00:19<00:00, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.20G/4.29G [00:19<00:00, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.24G/4.29G [00:19<00:00, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.29G/4.29G [00:19<00:00, 219MB/s]\n",
            "Fetching 20 files: 100% 20/20 [00:19<00:00,  1.00it/s]\n",
            "model downloaded to /content/dots.ocr/weights/DotsOCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor, AutoTokenizer\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from dots_ocr.utils import dict_promptmode_to_prompt\n",
        "\n",
        "model_path = \"./weights/DotsOCR\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)"
      ],
             "id": "MR6wmqGLAV0d",
        "outputId": "6310e2a5-dc15-44cd-acc3-f22536acf97e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abc6e04fa12a414b87605c57a1f87a52"
            }
          },
          
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCR'IN ÇALIŞTIĞI KISIM"
      ],
          },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "image_path = \"/content/sinav2.png\"\n",
        "prompt = \"\"\"Please output the layout information from the PDF image, including each layout element's bbox, its category, and the corresponding text content within the bbox.\n",
        "\n",
        "1. Bbox format: [x1, y1, x2, y2]\n",
        "\n",
        "2. Layout Categories: The possible categories are ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title'].\n",
        "\n",
        "3. Text Extraction & Formatting Rules:\n",
        "    - Picture: For the 'Picture' category, the text field should be omitted.\n",
        "    - Formula: Format its text as LaTeX.\n",
        "    - Table: Format its text as HTML.\n",
        "    - All Others (Text, Title, etc.): Format their text as Markdown.\n",
        "\n",
        "4. Constraints:\n",
        "    - The output text must be the original text from the image, with no translation.\n",
        "    - All layout elements must be sorted according to human reading order.\n",
        "\n",
        "5. Final Output: The entire output must be a single JSON object.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"image\": image_path\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": prompt}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# Preparation for inference\n",
        "text = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "image_inputs, video_inputs = process_vision_info(messages)\n",
        "inputs = processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    videos=video_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "\n",
        "inputs = inputs.to(\"cuda\")\n",
        "\n",
        "# Inference: Generation of the output\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=24000)\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(output_text)\n"
      ],
            "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[{\"bbox\": [10, 3, 377, 22], \"category\": \"Section-header\", \"text\": \"Soru 1. (15 puan) Algoritm a Analizi (Analysis of Algorithms)\"}, {\"bbox\": [10, 37, 568, 74], \"category\": \"Text\", \"text\": \"Aşağıdaki verilen kod parçaları için çalışma sürelerinin büyüme düzenini (order of growth)\\\\nN\\'nin bir fonksiyonu cinsinden --notasyonu ile belirtiniz.\"}, {\"bbox\": [10, 92, 90, 109], \"category\": \"Section-header\", \"text\": \"(a) (8 puan)\"}, {\"bbox\": [10, 127, 261, 194], \"category\": \"Text\", \"text\": \"int m = 0;\\\\nfor (int i = N; i >0; i--)\\\\n    for (int j = 0; j < i; j++)\\\\n        m++;\"}, {\"bbox\": [10, 194, 276, 257], \"category\": \"Text\", \"text\": \"Büyüme Düzeni: ~ O(N²)\"}, {\"bbox\": [10, 472, 90, 489], \"category\": \"Section-header\", \"text\": \"(b) (7 puan)\"}, {\"bbox\": [10, 506, 292, 574], \"category\": \"Text\", \"text\": \"int k = 0;\\\\nfor (int i = 1; i <= N; i++)\\\\n    for (int j = 1; j <= N; j++)\\\\n        k++;\"}, {\"bbox\": [10, 570, 363, 644], \"category\": \"Text\", \"text\": \"Büyüme Düzeni: ~ O(n · log(n))\"}]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# OCR'dan gelen çıktının bir liste içinde olduğunu varsayalım.\n",
        "# Eğer doğrudan string geliyorsa output_text[0] yerine output_text kullanın.\n",
        "try:\n",
        "    # 1. JSON dizesini bir Python listesine/sözlüğüne dönüştür\n",
        "    # Not: DotsOCR modeli bazen \"```json\" gibi işaretçilerle başlayabilir, bunları temizliyoruz.\n",
        "    clean_json_string = output_text[0].replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
        "    layout_data = json.loads(clean_json_string)\n",
        "\n",
        "    # 2. Tüm metin içeriklerini okuma sırasına göre birleştir\n",
        "    # Modelin çıktısı zaten okuma sırasına göre sıralanmış olmalı.\n",
        "    ogrenci_cevabi_parcalari = []\n",
        "    for element in layout_data:\n",
        "        # 'Picture' gibi metin içermeyen kategorileri atla [cite: 33]\n",
        "        if 'text' in element and element['text']:\n",
        "            ogrenci_cevabi_parcalari.append(element['text'])\n",
        "\n",
        "    # 3. Tüm metin parçalarını tek bir metin haline getir\n",
        "    ogrenci_cevabi_tamami = \"\\n\".join(ogrenci_cevabi_parcalari)\n",
        "\n",
        "    print(\"--- OCR'DAN AYIKLANAN ÖĞRENCİ CEVABI ---\")\n",
        "    print(ogrenci_cevabi_tamami)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Hata: OCR çıktısı geçerli bir JSON formatında değil. Hata: {e}\")\n",
        "    print(\"Alınan Çıktı:\", output_text[0])\n",
        "    ogrenci_cevabi_tamami = \"\" # Hata durumunda metni boş bırak\n",
        "\n",
        "# ÇIKTIDA MATEMATİKSEL SEMBOLLERE ÖZEL TERİMLER VAR, OCR DOĞRU ÇALIŞIYOR,\n",
        "# SADECE ONLAR MATEMATİKSEL GÖSTERİMLER İÇİN ÖRNEK: $\\mathbb{R}_2$"
      ],
            "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- OCR'DAN AYIKLANAN ÖĞRENCİ CEVABI ---\n",
            "Soru 1. (15 puan) Algoritm a Analizi (Analysis of Algorithms)\n",
            "Aşağıdaki verilen kod parçaları için çalışma sürelerinin büyüme düzenini (order of growth)\n",
            "N'nin bir fonksiyonu cinsinden --notasyonu ile belirtiniz.\n",
            "(a) (8 puan)\n",
            "int m = 0;\n",
            "for (int i = N; i >0; i--)\n",
            "    for (int j = 0; j < i; j++)\n",
            "        m++;\n",
            "Büyüme Düzeni: ~ O(N²)\n",
            "(b) (7 puan)\n",
            "int k = 0;\n",
            "for (int i = 1; i <= N; i++)\n",
            "    for (int j = 1; j <= N; j++)\n",
            "        k++;\n",
            "Büyüme Düzeni: ~ O(n · log(n))\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "from typing import List, Dict, Any\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# ============ 1) Robust OCR output parser ============\n",
        "\n",
        "def coerce_layout(output_text) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Accepts:\n",
        "      - raw string\n",
        "      - list[str] (e.g. ['[...]'])\n",
        "      - list[dict] (already parsed)\n",
        "      - code-fenced variations\n",
        "    Returns: list of dicts with keys like 'bbox', 'category', 'text'\n",
        "    \"\"\"\n",
        "    def _json_try(s: str):\n",
        "        s = s.strip()\n",
        "        # strip code fences ```json ... ```\n",
        "        s = re.sub(r\"^```(?:json)?\\s*\", \"\", s)\n",
        "        s = re.sub(r\"\\s*```$\", \"\", s)\n",
        "        # If the model returned extra text, try to extract the first JSON array\n",
        "        m = re.search(r\"\\[\\s*{.*}\\s*\\]\", s, flags=re.DOTALL)\n",
        "        if m:\n",
        "            s = m.group(0)\n",
        "        return json.loads(s)\n",
        "\n",
        "    # Already a list of dicts?\n",
        "    if isinstance(output_text, list) and output_text and isinstance(output_text[0], dict):\n",
        "        return output_text\n",
        "\n",
        "    # List with a single string?\n",
        "    if isinstance(output_text, list) and len(output_text) == 1 and isinstance(output_text[0], str):\n",
        "        try:\n",
        "            return _json_try(output_text[0])\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # fall through\n",
        "\n",
        "    # Bare string?\n",
        "    if isinstance(output_text, str):\n",
        "        try:\n",
        "            return _json_try(output_text)\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "    # Last resort: try json on each element if it's a list of strings\n",
        "    if isinstance(output_text, list) and all(isinstance(x, str) for x in output_text):\n",
        "        for s in output_text:\n",
        "            try:\n",
        "                return _json_try(s)\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    # Could not parse → return empty\n",
        "    return []\n",
        "\n",
        "# ============ 2) Q/A extractor (supports subparts like (a), (b)) ============\n",
        "\n",
        "PART_RE = re.compile(r\"^\\(?([a-z])\\)?(\\.|$|\\s)\", re.IGNORECASE)\n",
        "QUESTION_START_RE = re.compile(r\"(?:^|\\s)Soru\\s*(\\d+)\\b\", re.IGNORECASE)\n",
        "NUMBER_HEAD_RE = re.compile(r\"^(\\d+)[\\).]\")  # e.g. \"1)\" or \"1.\"\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "def extract_qas(layout_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Converts layout elements into a list of:\n",
        "      { qid: \"1a\", number: 1, part: \"a\", question: \"...\", answer: \"...\" }\n",
        "    Handles patterns like:\n",
        "      - \"Soru 1. ...\"\n",
        "      - \"(a) (8 puan)\" / \"a.\" / \"a)\"\n",
        "      - \"Cevap:\" / \"Büyüme Düzeni:\"\n",
        "    \"\"\"\n",
        "    if not layout_data:\n",
        "        return []\n",
        "\n",
        "    # Sort by reading order just in case\n",
        "    def key_bbox(e):\n",
        "        b = e.get(\"bbox\", [0, 0, 0, 0])\n",
        "        return (b[1], b[0])  # y1, x1\n",
        "\n",
        "    layout_sorted = sorted(layout_data, key=key_bbox)\n",
        "\n",
        "    qas = []\n",
        "    curr_qnum = None\n",
        "    curr_part = None\n",
        "    curr_qtext_parts = []\n",
        "    curr_ans_parts = []\n",
        "    have_answer_started = False\n",
        "\n",
        "    def flush():\n",
        "        nonlocal curr_qnum, curr_part, curr_qtext_parts, curr_ans_parts, have_answer_started\n",
        "        if curr_qnum is None or curr_part is None:\n",
        "            # nothing to flush\n",
        "            curr_qtext_parts, curr_ans_parts = [], []\n",
        "            have_answer_started = False\n",
        "            return\n",
        "        qid = f\"{curr_qnum}{curr_part}\"\n",
        "        qtext = normalize_text(\"\\n\".join(curr_qtext_parts))\n",
        "        ans = normalize_text(\"\\n\".join(curr_ans_parts))\n",
        "        if qtext or ans:\n",
        "            qas.append({\n",
        "                \"qid\": qid,\n",
        "                \"number\": curr_qnum,\n",
        "                \"part\": curr_part,\n",
        "                \"question\": qtext,\n",
        "                \"answer\": ans\n",
        "            })\n",
        "        # reset for next part\n",
        "        curr_part = None\n",
        "        curr_qtext_parts = []\n",
        "        curr_ans_parts = []\n",
        "        have_answer_started = False\n",
        "\n",
        "    for el in layout_sorted:\n",
        "        txt = el.get(\"text\", \"\")\n",
        "        if not txt:\n",
        "            continue\n",
        "        line = txt.strip()\n",
        "\n",
        "        # Detect \"Soru X\"\n",
        "        m_q = QUESTION_START_RE.search(line)\n",
        "        if m_q:\n",
        "            # New question block → flush any previous part\n",
        "            flush()\n",
        "            curr_qnum = int(m_q.group(1))\n",
        "            curr_part = None\n",
        "            curr_qtext_parts = [line]\n",
        "            curr_ans_parts = []\n",
        "            have_answer_started = False\n",
        "            continue\n",
        "\n",
        "        # Detect explicit numeric start \"1.\" if \"Soru\" wasn't present\n",
        "        if curr_qnum is None:\n",
        "            m_head = NUMBER_HEAD_RE.match(line)\n",
        "            if m_head:\n",
        "                flush()\n",
        "                curr_qnum = int(m_head.group(1))\n",
        "                curr_part = None\n",
        "                curr_qtext_parts = [line]\n",
        "                curr_ans_parts = []\n",
        "                have_answer_started = False\n",
        "                continue\n",
        "\n",
        "        # Detect subpart markers like \"(a)\", \"a)\", \"a.\"\n",
        "        m_p = PART_RE.match(line)\n",
        "        if m_p:\n",
        "            # Starting a new part → flush previous part\n",
        "            if curr_part is not None:\n",
        "                flush()\n",
        "            curr_part = m_p.group(1).lower()\n",
        "            curr_qtext_parts = [line]\n",
        "            curr_ans_parts = []\n",
        "            have_answer_started = False\n",
        "            continue\n",
        "\n",
        "        # If a question is active but no part yet, keep appending to the question text\n",
        "        # until we see a part marker.\n",
        "        if curr_qnum is not None and curr_part is None:\n",
        "            curr_qtext_parts.append(line)\n",
        "            continue\n",
        "\n",
        "        # Answer triggers\n",
        "        is_answer_trigger = (\n",
        "            re.search(r\"\\bcevap\\b\", line, re.IGNORECASE) or\n",
        "            re.search(r\"büyüme\\s*düzeni\", line, re.IGNORECASE) or\n",
        "            re.search(r\"\\byanıt\\b\", line, re.IGNORECASE)\n",
        "        )\n",
        "\n",
        "        if curr_qnum is not None and curr_part is not None:\n",
        "            if is_answer_trigger:\n",
        "                have_answer_started = True\n",
        "                # Normalize common prefixes\n",
        "                line_clean = re.sub(r\"(?i)^(a\\.\\s*)?cevap\\s*:?\\s*\", \"\", line)\n",
        "                line_clean = re.sub(r\"(?i)^büyüme\\s*düzeni\\s*:?\\s*\", \"\", line_clean)\n",
        "                curr_ans_parts.append(line_clean.strip())\n",
        "            else:\n",
        "                # Before answer starts → keep building the subpart question\n",
        "                if not have_answer_started:\n",
        "                    curr_qtext_parts.append(line)\n",
        "                else:\n",
        "                    # After answer started → multi-line answer continuation\n",
        "                    curr_ans_parts.append(line)\n",
        "\n",
        "    # Flush last part\n",
        "    if curr_qnum is not None and curr_part is not None:\n",
        "        flush()\n",
        "\n",
        "    return qas\n",
        "\n",
        "# ============ 3) Grading (safe against empty results) ============\n",
        "\n",
        "def grade_qas(qas: List[Dict[str, Any]], answer_key_dict: Dict[str, str]):\n",
        "    \"\"\"\n",
        "    qas: output of extract_qas()\n",
        "    answer_key_dict: keys like \"1a\", \"1b\"\n",
        "    Returns: (results_list, overall_average)\n",
        "    \"\"\"\n",
        "    # Pick a multilingual ST model to be robust in TR/EN\n",
        "    st_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "    results = []\n",
        "    for qa in qas:\n",
        "        qid = qa[\"qid\"]\n",
        "        student_answer = qa.get(\"answer\", \"\")\n",
        "        key_answer = answer_key_dict.get(qid, \"\")\n",
        "        if not student_answer or not key_answer:\n",
        "            score = 0.0\n",
        "        else:\n",
        "            emb_s = st_model.encode(student_answer, convert_to_tensor=True)\n",
        "            emb_k = st_model.encode(key_answer, convert_to_tensor=True)\n",
        "            score = float(util.cos_sim(emb_s, emb_k).item() * 100.0)\n",
        "\n",
        "        results.append({\n",
        "            \"qid\": qid,\n",
        "            \"question\": qa.get(\"question\", \"\"),\n",
        "            \"student_answer\": student_answer,\n",
        "            \"key_answer\": key_answer,\n",
        "            \"score\": score\n",
        "        })\n",
        "\n",
        "    overall = (sum(r[\"score\"] for r in results) / len(results)) if results else 0.0\n",
        "    return results, overall\n",
        "\n",
        "# ============ 4) Example usage with your sample OCR output ============\n",
        "\n",
        "layout = coerce_layout(output_text)\n",
        "qas = extract_qas(layout)\n",
        "\n",
        "# Fill your answer key here (keys like \"1a\", \"1b\")\n",
        "# (These are examples; replace with your ground truth.)\n",
        "answer_key_dict = {\n",
        "    \"1a\": \"O(N²)\",\n",
        "    \"1b\": \"O(N*log(N))\"\n",
        "}\n",
        "\n",
        "results, overall = grade_qas(qas, answer_key_dict)\n",
        "\n",
        "print(\"--- PARSED Q/A ---\")\n",
        "for qa in qas:\n",
        "    print(f\"{qa['qid']}:\")\n",
        "    print(\"Q:\", qa['question'])\n",
        "    print(\"A:\", qa['answer'])\n",
        "    print()\n",
        "\n",
        "print(\"--- GRADES ---\")\n",
        "correct_ans = 0\n",
        "for r in results:\n",
        "    print(f\"{r['qid']}: {r['score']:.2f}/100\")\n",
        "    if r['score'] >= 85:\n",
        "        correct_ans += 1\n",
        "print(f\"Overall: {overall:.2f}/100\")\n",
        "print(f\"Correct answers: {correct_ans}/{len(results)}\")\n",
        "res = correct_ans / len(results) * 100\n",
        "print(\"Final Grade\" , res)"
      ],
            "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PARSED Q/A ---\n",
            "1a:\n",
            "Q: (a) (8 puan) int m = 0; for (int i = N; i >0; i--) for (int j = 0; j < i; j++) m++;\n",
            "A: ~ O(N²)\n",
            "\n",
            "1b:\n",
            "Q: (b) (7 puan) int k = 0; for (int i = 1; i <= N; i++) for (int j = 1; j <= N; j++) k++;\n",
            "A: ~ O(n · log(n))\n",
            "\n",
            "--- GRADES ---\n",
            "1a: 90.78/100\n",
            "1b: 90.14/100\n",
            "Overall: 90.46/100\n",
            "Correct answers: 2/2\n",
            "Final Grade 100.0\n"
          ]
        }
      ]
    }
  ]
}